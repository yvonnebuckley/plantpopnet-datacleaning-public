#### Location errors in 14 rows in 2016. Latitude errors are very large.
#### Fix by setting these to match the other 513 rows?
mydata[mydata$site_code == "TNC","transect_Lon_start"] <- -123.1665
mydata[mydata$site_code == "TNC","transect_Lon_stop"]  <-  -123.166467
site_checks_resolved[4] <- "TNC"
TNM <- droplevels(mydata[mydata$site_code == "TNM",])
TNM %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
TNM %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
mydata[mydata$site_code == "TNM","transect_Lon_start"] <- -7.61744
mydata[mydata$site_code == "TNM","transect_Lon_stop"]  <-  -7.61743
site_checks_resolved[5] <- "TNM"
TW <- droplevels(mydata[mydata$site_code == "TW",])
TW %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
TW %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
TW_LatStr <- unique(TW$transect_Lat_start[TW$c_year == "2016"])
TW_LonStp <- unique(TW$transect_Lon_stop[TW$c_year == "2016"])
mydata[mydata$site_code == "TW","transect_Lat_start"] <- TW_LatStr
mydata[mydata$site_code == "TW","transect_Lon_stop"]  <-  TW_LonStp
site_checks_resolved[6] <- "TW"
## next one - WIN site_checks[7]
WIN <- droplevels(mydata[mydata$site_code == "WIN",])
WIN %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
WIN %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
unique(WIN$transect_Lon_start[WIN$c_year == "2018"])
#missing a minus in transect_Lon_start & transect_Lon_stop in 2018
mydata[mydata$site_code == "WIN","transect_Lon_start"] <- -1.3081
mydata[mydata$site_code == "WIN","transect_Lon_stop"] <- -1.3081
site_checks_resolved[7] <- "WIN"
if(sum(is.na(site_checks_resolved)) > 0) {
warning("These sites require more information before proper GPS fixes can be applied:")
warning(paste(site_checks[is.na(site_checks_resolved)], "  "))
}
###### one last look at check_table
check_table <- as.data.frame( mydata %>%
group_by(site_code, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop)))
check_table
#################################################################################################################
## Error 1
##### Checking which sites have NA's for the transect start values #####
#### select rows in mydata where transect_Lat_start = NA
x1 <- which(is.na(mydata$transect_Lat_start))
### dataset containing only those rows with nas in transect coordinates.
na_coords <- mydata[x1,]
na_coords <- droplevels(na_coords)
#### vector containing site codes with no coordinates given
na_site_coords <- levels(na_coords$site_code)
#### creates dataset containing rows for which transect_Lat_start != NA
has_coords <- droplevels(mydata[-x1,])
#### vector containing sites with coordinates
has_site_coords <- levels(has_coords$site_code)
#### Check which sites have no transect coordinates in either file.
sites_no_coords <- setdiff(na_site_coords,has_site_coords)
##### No transect coordinates were supplied for these sites in the original
#### files no fix needs to be applied here. Leave data as is.
if(length(sites_no_coords>0)) {
warning("Error 1: these sites have no transect coordinates - contact site coordinator. No fix applied.")
sites_no_coords
}
### which sites has both transects with and without coordinate data
sites_with_without <- intersect(na_site_coords,has_site_coords)
if(length(sites_with_without) > 0) {
warning("Error 2: these sites have transects both with and without coordinate data")
sites_with_without
}
BG <- subset(mydata, site_code == "BG")
summary(BG)
BG
knitr::opts_knit$set(root.dir = "~/Plantpopnet-Data-Cleaning/Master")
library(dplyr)
library(stringr)
knitr::opts_knit$set(root.dir = "~/Plantpopnet-Data-Cleaning/Master")
library(dplyr)
library(stringr)
#for now we will use a static test version of the data. source codes can be modified in future to read in updated master files
data_orig <- read.csv("fullPPN_dataset_2019-06-20_.csv",header = T, na.strings = c("NA", "", "Na", "na", "nA"))
mydata <- data_orig
sitedata <- read.csv("Coordinates_Feb2019_site_level.csv", header = T)
source("Global1_remove_na_rows_func.R")
names(mydata)[names(mydata) == "rosette_number"] <- "rosette_ID"
## create "not in" operator
'%nin%' = Negate('%in%')
# levels(mydata$site_code)
source("var1_site_code_MB_YB.R")
# levels(mydata$site_code)
Sys.setlocale('LC_ALL','C') ## needed to deal with some encoding issues (Mac to PC) if all ok print-out will read "[1] "C/C/C/C/C/en_IE.UTF-8" " . No action necessary
source("var2-5_coordinate_locations_RK_YB.R")
knitr::opts_knit$set(root.dir = "~/Plantpopnet-Data-Cleaning/Master")
library(dplyr)
library(stringr)
#for now we will use a static test version of the data. source codes can be modified in future to read in updated master files
data_orig <- read.csv("fullPPN_dataset_2019-06-20_.csv",header = T, na.strings = c("NA", "", "Na", "na", "nA"))
mydata <- data_orig
sitedata <- read.csv("Coordinates_Feb2019_site_level.csv", header = T)
source("Global1_remove_na_rows_func.R")
names(mydata)[names(mydata) == "rosette_number"] <- "rosette_ID"
## create "not in" operator
'%nin%' = Negate('%in%')
# levels(mydata$site_code)
source("var1_site_code_MB_YB.R")
# levels(mydata$site_code)
# levels(mydata$site_code)
source("var1_site_code_MB_YB.R")
# levels(mydata$site_code)
Sys.setlocale('LC_ALL','C') ## needed to deal with some encoding issues (Mac to PC) if all ok print-out will read "[1] "C/C/C/C/C/en_IE.UTF-8" " . No action necessary
#################################################################################################################
## Error 1
##### Checking which sites have NA's for the transect start values #####
#### select rows in mydata where transect_Lat_start = NA
x1 <- which(is.na(mydata$transect_Lat_start))
### dataset containing only those rows with nas in transect coordinates.
na_coords <- mydata[x1,]
na_coords <- droplevels(na_coords)
#### vector containing site codes with no coordinates given
na_site_coords <- levels(na_coords$site_code)
#### creates dataset containing rows for which transect_Lat_start != NA
has_coords <- droplevels(mydata[-x1,])
#### vector containing sites with coordinates
has_site_coords <- levels(has_coords$site_code)
#### Check which sites have no transect coordinates in either file.
sites_no_coords <- setdiff(na_site_coords,has_site_coords)
##### No transect coordinates were supplied for these sites in the original
#### files no fix needs to be applied here. Leave data as is.
if(length(sites_no_coords>0)) {
warning("Error 1: these sites have no transect coordinates - contact site coordinator. No fix applied.")
sites_no_coords
}
##### No transect coordinates were supplied for these sites in the original
#### files no fix needs to be applied here. Leave data as is.
sites_no_coords
if(length(sites_no_coords>0)) {
warning("Error 1: these sites have no transect coordinates - contact site coordinator. No fix applied.")
}
##### No transect coordinates were supplied for these sites in the original
#### files no fix needs to be applied here. Leave data as is.
print(sites_no_coords)
print(sites_with_without)
### which sites has both transects with and without coordinate data
sites_with_without <- intersect(na_site_coords,has_site_coords)
print(sites_with_without)
if(length(sites_with_without) > 0) {
warning("Error 2: these sites have transects both with and without coordinate data")
}
#### select rows in mydata where transect_Lon_stop = NA
x3 <- which(is.na(mydata$transect_Lon_stop))
### dataset containing only those rows with nas in transect coordinates.
na_coords <- mydata[x3,]
na_coords <- droplevels(na_coords)
#### vector containing sites with no coordinates given
na_site_coords <- levels(na_coords$site_code)
#### creates dataset containing rows for which transect_Lon_Stop != NA
has_coords <- droplevels(mydata[-x3,])
#### vector containing sites with no coordinates given
has_site_coords <- levels(has_coords$site_code)
BG <- droplevels(mydata[mydata$site_code == "BG",])
###  Create dataset for just 2016
BG_2016 <- BG[BG$c_year == "2016",]
#### Create dataset of just T1 in 2016
BG_2016_T1 <- droplevels(BG_2016[BG_2016$transect == "T1",])
#### find rows in mydata for site code BG, transect T1 and year 2015
x2 <- which(mydata$site_code == "BG" & mydata$transect == "T1" & mydata$c_year == "2015")
mydata$transect_Lat_start[x2] <-  levels(BG_2016_T1$transect_Lat_start)
mydata$transect_Lon_start[x2] <- levels(BG_2016_T1$transect_Lon_start) # Returns -  "7.480596"
mydata$transect_Lat_stop[x2] <- levels(BG_2016_T1$transect_Lat_stop) # Returns -  "61.448075"
mydata$transect_Lon_stop[x2] <- levels(BG_2016_T1$transect_Lon_stop) #
BG_2016_T2 <- droplevels(BG_2016[BG_2016$transect == "T2",])
####
x3 <- which(mydata$site_code == "BG" & mydata$transect == "T2" & mydata$c_year == "2015")
###
{
mydata$transect_Lat_start[x3] <-  levels(BG_2016_T2$transect_Lat_start) # "61.448026"
mydata$transect_Lon_start[x3] <- levels(BG_2016_T2$transect_Lon_start) # Returns - "7.480639"
mydata$transect_Lat_stop[x3] <- levels(BG_2016_T2$transect_Lat_stop) # Returns -  "61.448072"
mydata$transect_Lon_stop[x3] <- levels(BG_2016_T2$transect_Lon_stop) # Returns - "7.480614"
print("Error 2 fixed for BG")
}
mydata$transect_Lat_start <- as.character(mydata$transect_Lat_start)
mydata$transect_Lat_stop  <- as.character(mydata$transect_Lat_stop)
mydata$transect_Lon_start <- as.character(mydata$transect_Lon_start)
mydata$transect_Lon_stop <- as.character(mydata$transect_Lon_stop)
### change coords based on online coordinate converter as follows.
# names(mydata)
{
mydata[mydata$site_code == "PC","transect_Lat_start"] <- "38.5177007"
mydata[mydata$site_code == "PC","transect_Lon_start"]  <- "-121.7643222"
mydata[mydata$site_code == "PC","transect_Lat_stop"] <- "38.5176821"
mydata[mydata$site_code == "PC","transect_Lon_stop"]  <- "-121.7642651"
print("Error 3 fixed for PC")
}
###################################################################################################
#### Error 4  on Mac there are some odd transect_lat_start values for VA site e.g. \24037.95865 & JE site
## - perhaps a Mac/PC encoding issue? (YB)
## YB 20/06/19 this problem occurs on YB laptop (Mac) but not on desktop (Mac)!
err4 <- "Error 4: site with strange encoding in transect latitude"
err4b <- "Error 4: site with strange encoding in transect longitude"
x3 <- grepl("\240", mydata$transect_Lat_start)
weird_sites <- droplevels(unique(mydata$site_code[x3]))
if(length(weird_sites) > 0 ) {
warning(err4)
print(weird_sites)
mydata$transect_Lat_start[x3] <- gsub("\240", "", mydata$transect_Lat_start[x3] )
print("Error 4 fixed for transect_lat_start weird sites above")
}
x5 <- grepl("50\260", mydata$transect_Lat_start)
weird_sites2 <- droplevels(unique(mydata$site_code[x5]))  ##JE
if(length(weird_sites2) > 0) {
warning(err4)
print(weird_sites2)
mydata$transect_Lat_start[x5] <- 50.95192
print("Error 4 fixed for weird sites above")
}
x6 <- grepl("50\260", mydata$transect_Lat_stop)
weird_sites3 <- droplevels(unique(mydata$site_code[x6])) #JE
if(length(weird_sites3) > 0) {
warning(err4)
print(weird_sites3)
mydata$transect_Lat_stop[x6] <- 50.95192
print("Error 4 fixed for weird sites above")
}
x7 <- grepl("11\260", mydata$transect_Lon_start)
weird_sites4 <- droplevels(unique(mydata$site_code[x7])) #JE
if(length(weird_sites4) > 0) {
warning(err4b)
print(weird_sites4)
mydata$transect_Lon_start[x7] <- 11.62282
print("Error 4 fixed for weird sites above")
}
x8 <- grepl("11\260", mydata$transect_Lon_stop)
weird_sites5 <- droplevels(unique(mydata$site_code[x8])) #JE
if(length(weird_sites5) > 0) {
warning(err4b)
print(weird_sites5)
mydata$transect_Lon_stop[x8] <- 11.62282
print("Error 4 fixed for weird sites above")
}
#### Grab all rows with an N in the latitude coordinates, for examination
N_issues <-droplevels(mydata[which(grepl("N", mydata$transect_Lat_start)==T),])
N_issues_sites <- unique(N_issues$site_code)
if(length(N_issues_sites) > 0 ) {
print(N_issues_sites)
warning("N included in transect latitude start for the sites above")
}
sites <- sitedata
EE <- droplevels(mydata[mydata$site_code == "EE",])
HAS <- droplevels(mydata[mydata$site_code == "HAS",])
#### IO check for letters in coordinates ####
IO <- droplevels(mydata[mydata$site_code == "IO",])
N_issues <-droplevels(mydata[which(grepl("N", mydata$transect_Lat_start)==T),])
{
mydata$transect_Lon_stop[which(mydata$transect_Lon_stop == "009.51671 W")] <- "-9.51671"
mydata$transect_Lon_start[which(mydata$transect_Lon_start == "009.51672 W")] <- "-9.51672"
warning("site IO fixed here, W removed from coordinates")
}
#### OR_SS check for letters in coordinates ####
OR_SS <- droplevels(mydata[mydata$site_code == "OR_SS",])
### create vector of letters and characters to remove, this will be 'j' in the loop
replace1 <- c(" ", "N", "E", "S", "W")
### create vector columns to remove 'replace1' from, this wil be 'i' in the loop
cols_trans <- c("transect_Lat_start", "transect_Lon_start",
"transect_Lon_stop", "transect_Lat_stop")
for (j in replace1) {
for(i in cols_trans) {
mydata[,i] <- gsub(pattern = j,
x = mydata[,i],
"")
# print(i)
}
# print(j)
warning("Error 5 fixed: all letters and spaces removed from coordinates columns")
}
### this converts each transect column to numeric
for(i in cols_trans) {
mydata[,i] <- as.numeric( mydata[,i])
# print(i)
}
check_table <- as.data.frame( mydata %>%
group_by(site_code, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop)))
err1 <- which(rowSums(check_table[,3:6]) != 4)
tocheck2 <- check_table[err1,]
site_checks <- unique(tocheck2$site_code)
# make new variable site_checks_resolved which will hold names of sites from site_checks that have been sorted out
site_checks_resolved <- rep(NA, length(site_checks))
#site_checks[1]
CDF <- droplevels(mydata[mydata$site_code == "CDF",])
table(CDF$transect_Lat_start, CDF$transect)
#Lat
mydata[mydata$site_code == "CDF" & mydata$transect == "T1","transect_Lat_start"] <- 51.899639
mydata[mydata$site_code == "CDF" & mydata$transect == "T1","transect_Lat_stop"] <- 51.899639
mydata[mydata$site_code == "CDF" & mydata$transect == "T2","transect_Lat_start"] <- 51.899611
mydata[mydata$site_code == "CDF" & mydata$transect == "T2","transect_Lat_stop"] <- 51.899611
#Lon
mydata[mydata$site_code == "CDF" & mydata$transect == "T1","transect_Lon_start"] <- -8.485972
mydata[mydata$site_code == "CDF" & mydata$transect == "T1","transect_Lon_stop"] <- -8.485889
mydata[mydata$site_code == "CDF" & mydata$transect == "T2","transect_Lon_start"] <- -8.485944
mydata[mydata$site_code == "CDF" & mydata$transect == "T2","transect_Lon_stop"] <- -8.485889
site_checks_resolved[1] <- "CDF"
## next one - SBK (site_checks[2])
SBK <- droplevels(mydata[mydata$site_code == "SBK",])
SBK %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
SBK %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
SBK1 <- SBK[SBK$transect == "T1",]
#table(SBK1$transect_Lat_start, SBK1$c_year)
#table(SBK1$transect_Lon_start, SBK1$c_year)
#table(SBK1$transect_Lat_stop, SBK1$c_year)
#table(SBK1$transect_Lon_start, SBK1$c_year)
#no values for transect in 2016. fill with values from 2018
mydata[mydata$site_code == "SBK","transect_Lat_start"] <- 47.40025
mydata[mydata$site_code == "SBK","transect_Lat_stop"]  <- 47.40025
mydata[mydata$site_code == "SBK","transect_Lon_start"] <- 19.15878
mydata[mydata$site_code == "SBK","transect_Lon_stop"]  <- 19.15878
site_checks_resolved[2] <- "SBK"
SC <- droplevels(mydata[mydata$site_code == "SC",])
SC %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
SC %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
SCT2 <- SC[SC$transect == "T2",]
SCT1 <- SC[SC$transect =="T1",]
table(SCT2$transect_Lon_start, SCT2$c_year)
#             2015 2016 2017 2018
#-008.9923    66    0    0    0
#-008.99239    0    0   85   72
#-8.99239      0   88    0    0
table(SCT2$transect_Lon_stop, SCT2$c_year)
#### inconsistencies in Transect_Lon_stop across all years
mydata[mydata$site_code == "SC" & mydata$transect == "T2","transect_Lon_start"] <- -8.99239
mydata[mydata$site_code == "SC" & mydata$transect == "T2","transect_Lon_stop"] <- -8.99235
mydata[mydata$site_code == "SC" & mydata$transect == "T1","transect_Lon_start"] <- -8.99231
mydata[mydata$site_code == "SC" & mydata$transect == "T1","transect_Lon_stop"] <- -8.99229
site_checks_resolved[3] <- "SC"
TNC <- droplevels(mydata[mydata$site_code == "TNC",])
TNC %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
TNC %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
#table(TNC$transect_Lat_start, TNC$c_year)
#table(TNC$transect_Lat_stop, TNC$c_year)
### strange coordinates for 14 rows in 2016. Off by 100's of kms!
### Set these to match the other coordinates for this transect?
mydata[mydata$site_code == "TNC","transect_Lat_start"] <- 44.03775
mydata[mydata$site_code == "TNC","transect_Lat_stop"]  <-  44.03775
#### Location errors in 14 rows in 2016. Latitude errors are very large.
#### Fix by setting these to match the other 513 rows?
mydata[mydata$site_code == "TNC","transect_Lon_start"] <- -123.1665
mydata[mydata$site_code == "TNC","transect_Lon_stop"]  <-  -123.166467
site_checks_resolved[4] <- "TNC"
TNM <- droplevels(mydata[mydata$site_code == "TNM",])
TNM %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
TNM %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
mydata[mydata$site_code == "TNM","transect_Lon_start"] <- -7.61744
mydata[mydata$site_code == "TNM","transect_Lon_stop"]  <-  -7.61743
site_checks_resolved[5] <- "TNM"
TW <- droplevels(mydata[mydata$site_code == "TW",])
TW %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
TW %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
TW_LatStr <- unique(TW$transect_Lat_start[TW$c_year == "2016"])
TW_LonStp <- unique(TW$transect_Lon_stop[TW$c_year == "2016"])
mydata[mydata$site_code == "TW","transect_Lat_start"] <- TW_LatStr
mydata[mydata$site_code == "TW","transect_Lon_stop"]  <-  TW_LonStp
site_checks_resolved[6] <- "TW"
## next one - WIN site_checks[7]
WIN <- droplevels(mydata[mydata$site_code == "WIN",])
WIN %>%
group_by(transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
WIN %>%
group_by(c_year, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop))
unique(WIN$transect_Lon_start[WIN$c_year == "2018"])
#missing a minus in transect_Lon_start & transect_Lon_stop in 2018
mydata[mydata$site_code == "WIN","transect_Lon_start"] <- -1.3081
mydata[mydata$site_code == "WIN","transect_Lon_stop"] <- -1.3081
site_checks_resolved[7] <- "WIN"
if(sum(is.na(site_checks_resolved)) > 0) {
warning("These sites require more information before proper GPS fixes can be applied:")
warning(paste(site_checks[is.na(site_checks_resolved)], "  "))
}
###### one last look at check_table
check_table <- as.data.frame( mydata %>%
group_by(site_code, transect) %>%
summarise(n_trans_lat_start = n_distinct(transect_Lat_start),
n_trans_lat_stop = n_distinct(transect_Lat_stop),
n_trans_lon_start = n_distinct(transect_Lon_start),
n_trans_lon_stop = n_distinct(transect_Lon_stop)))
check_table
knitr::opts_knit$set(root.dir = "~/Plantpopnet-Data-Cleaning/Master")
library(dplyr)
library(stringr)
#for now we will use a static test version of the data. source codes can be modified in future to read in updated master files
data_orig <- read.csv("fullPPN_dataset_2019-06-20_.csv",header = T, na.strings = c("NA", "", "Na", "na", "nA"))
mydata <- data_orig
sitedata <- read.csv("Coordinates_Feb2019_site_level.csv", header = T)
source("Global1_remove_na_rows_func.R")
knitr::opts_knit$set(root.dir = "~/Plantpopnet-Data-Cleaning/Master")
library(dplyr)
library(stringr)
#for now we will use a static test version of the data. source codes can be modified in future to read in updated master files
data_orig <- read.csv("fullPPN_dataset_2019-06-20_.csv",header = T, na.strings = c("NA", "", "Na", "na", "nA"))
mydata <- data_orig
sitedata <- read.csv("Coordinates_Feb2019_site_level.csv", header = T)
source("Global1_remove_na_rows_func.R")
names(mydata)[names(mydata) == "rosette_number"] <- "rosette_ID"
# levels(mydata$site_code)
source("var1_site_code_MB_YB.R")
# levels(mydata$site_code)
Sys.setlocale('LC_ALL','C') ## needed to deal with some encoding issues (Mac to PC) if all ok print-out will read "[1] "C/C/C/C/C/en_IE.UTF-8" " . No action necessary
source("var2-5_coordinate_locations_RK_YB.R")
knitr::opts_knit$set(root.dir = "~/Plantpopnet-Data-Cleaning/Master")
library(dplyr)
library(stringr)
#for now we will use a static test version of the data. source codes can be modified in future to read in updated master files
data_orig <- read.csv("fullPPN_dataset_2019-06-20_.csv",header = T, na.strings = c("NA", "", "Na", "na", "nA"))
mydata <- data_orig
sitedata <- read.csv("Coordinates_Feb2019_site_level.csv", header = T)
source("Global1_remove_na_rows_func.R")
names(mydata)[names(mydata) == "rosette_number"] <- "rosette_ID"
## create "not in" operator
'%nin%' = Negate('%in%')
# levels(mydata$site_code)
source("var1_site_code_MB_YB.R")
# levels(mydata$site_code)
Sys.setlocale('LC_ALL','C') ## needed to deal with some encoding issues (Mac to PC) if all ok print-out will read "[1] "C/C/C/C/C/en_IE.UTF-8" " . No action necessary
source("var2-5_coordinate_locations_RK_YB.R")
